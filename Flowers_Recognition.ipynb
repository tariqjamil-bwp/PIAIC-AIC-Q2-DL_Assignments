{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import struct\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "IMAGE_HEIGHT = 160 # 320\n",
    "IMAGE_WIDTH = 120 # 240\n",
    "size = (IMAGE_HEIGHT, IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dandelion', 'tulip', 'sunflower', 'rose', 'daisy']\n"
     ]
    }
   ],
   "source": [
    "# Data upload from files to arrays\n",
    "# The data set is stored under local hard disk in subfolder 'flowers'\n",
    "\n",
    "main_folder = \"flowers/\"               # path of the flowers data on current drive/directory (same as code directory)\n",
    "sub_folders = os.listdir(main_folder)  # List out the sub_directories which are named after folower classes\n",
    "print(sub_folders)\n",
    "\n",
    "image_array=[]\n",
    "class_array=[]\n",
    "    \n",
    "for flower_directory in sub_folders:\n",
    "    for file in os.listdir(os.path.join(main_folder, flower_directory)):\n",
    "        \n",
    "        if file.endswith(\"jpg\"):\n",
    "            image_path= os.path.join(main_folder, flower_directory,  file)\n",
    "            #image  = cv2.imread(image_path)\n",
    "            image  = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image1 = cv2.resize(image, size, interpolation = cv2.INTER_AREA)\n",
    "            image2 = image1.reshape(IMAGE_HEIGHT*IMAGE_WIDTH*1)\n",
    "            image_array.append(image2)\n",
    "            class_array.append(flower_directory)   # storing classe of flowers\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [],
   "source": [
    "# Normalizing & enccoding the data.\n",
    "\n",
    "images = np.array(image_array)   # conversion of list to numpy array of images\n",
    "images_data = images.astype(float)/255.   # ranginging RGB data between 0-1 and float type.\n",
    "class_labels = pd.get_dummies(class_array).values.argmax(1)  # encoding flower classes into numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x, y = shuffle(images_data, class_labels)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1616,
     "status": "aborted",
     "timestamp": 1617089068011,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "QCVbB_672DJd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.6 # 60%\n",
    "ratio_test  = 0.4 # 40%\n",
    "\n",
    "# Produces 40% test split.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=ratio_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1616618211034,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "s6Q0t3OA7zOo"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Flatten(input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH,3)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(5,   activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1616618678144,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "cDkTCRbw7zOp"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers, regularizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.001, nesterov=True)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "\n",
    "model.compile(optimizer = sgd, #'rmsprop',\n",
    "              loss      = 'sparse_categorical_crossentropy',\n",
    "              metrics   = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16758,
     "status": "ok",
     "timestamp": 1616618698793,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "g-G5kMoF7zOr",
    "outputId": "3be1e225-002d-48fe-8064-728204fab5d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "41/41 [==============================] - 1s 5ms/step - loss: 1.6350 - accuracy: 0.2239\n",
      "Epoch 2/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.5679 - accuracy: 0.2920\n",
      "Epoch 3/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.5585 - accuracy: 0.2839\n",
      "Epoch 4/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.5535 - accuracy: 0.2890\n",
      "Epoch 5/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.5291 - accuracy: 0.3210\n",
      "Epoch 6/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.5165 - accuracy: 0.3323\n",
      "Epoch 7/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.5059 - accuracy: 0.3253\n",
      "Epoch 8/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.4984 - accuracy: 0.3394\n",
      "Epoch 9/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.4877 - accuracy: 0.3471\n",
      "Epoch 10/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4831 - accuracy: 0.3555\n",
      "Epoch 11/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4837 - accuracy: 0.3303\n",
      "Epoch 12/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4798 - accuracy: 0.3514\n",
      "Epoch 13/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4610 - accuracy: 0.3488\n",
      "Epoch 14/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4685 - accuracy: 0.3486\n",
      "Epoch 15/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4494 - accuracy: 0.3681\n",
      "Epoch 16/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.4315 - accuracy: 0.3823\n",
      "Epoch 17/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4489 - accuracy: 0.3633\n",
      "Epoch 18/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4344 - accuracy: 0.3785\n",
      "Epoch 19/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4293 - accuracy: 0.4051\n",
      "Epoch 20/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4428 - accuracy: 0.3956\n",
      "Epoch 21/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4337 - accuracy: 0.3869\n",
      "Epoch 22/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4179 - accuracy: 0.4036\n",
      "Epoch 23/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4138 - accuracy: 0.4102\n",
      "Epoch 24/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4051 - accuracy: 0.4135\n",
      "Epoch 25/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.4041 - accuracy: 0.4130\n",
      "Epoch 26/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.4011 - accuracy: 0.4105\n",
      "Epoch 27/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4035 - accuracy: 0.4212\n",
      "Epoch 28/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3933 - accuracy: 0.4393\n",
      "Epoch 29/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.4040 - accuracy: 0.4131\n",
      "Epoch 30/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3968 - accuracy: 0.4033\n",
      "Epoch 31/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3841 - accuracy: 0.4365\n",
      "Epoch 32/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3799 - accuracy: 0.4289\n",
      "Epoch 33/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3843 - accuracy: 0.4288\n",
      "Epoch 34/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3722 - accuracy: 0.4265\n",
      "Epoch 35/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.3778 - accuracy: 0.4361\n",
      "Epoch 36/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3519 - accuracy: 0.4440\n",
      "Epoch 37/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3541 - accuracy: 0.4629\n",
      "Epoch 38/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3494 - accuracy: 0.4476\n",
      "Epoch 39/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3523 - accuracy: 0.4564\n",
      "Epoch 40/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.4499\n",
      "Epoch 41/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3380 - accuracy: 0.4654\n",
      "Epoch 42/60\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1.3459 - accuracy: 0.4720\n",
      "Epoch 43/60\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 1.3319 - accuracy: 0.4637\n",
      "Epoch 44/60\n",
      " 1/41 [..............................] - ETA: 0s - loss: 1.4789 - accuracy: 0.3438"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=60, batch_size=64,\n",
    "                    #validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1616619205172,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "XbaOnEpE7zOs",
    "outputId": "2711a9fd-7c9f-4707-d582-3e4c04d9b7c8"
   },
   "outputs": [],
   "source": [
    "history_dict=history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1616618762615,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "2BSBPe0-9YuM",
    "outputId": "06993946-833f-4460-c830-5520c3fc693c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1616619225341,
     "user": {
      "displayName": "Tariq Jamil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDTWFYRmAzAYPlKEXPBbLUin4uLOPxYf0jwdLNofE=s64",
      "userId": "14932491825632509938"
     },
     "user_tz": -300
    },
    "id": "a0CHQAwQY0_I",
    "outputId": "1968b917-c4dd-49ec-9e77-c4dd34f1da10"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pridcting on test values\n",
    "\n",
    "test_loss_score, test_accuracy_score = model.evaluate(x_test, y_test)\n",
    "\n",
    "# display test loss\n",
    "display(test_loss_score)\n",
    "\n",
    "# display test predic \n",
    "display (test_accuracy_score)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
